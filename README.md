# DEEP-LEARNING-PROJECT

*COMPANY* : CODTECH IT SOLUTION

*NAME* : VAISHNAVI DAHILKAR

*INTERN ID* : CT4MDL987

*DOMAIN* : DATA SCIENCE

*DURATION* : 4 MONTH

*MENTOR* : NEELA SANTOSH

*DESCRIPTION* : 

THIS DEEP LEARNING PROJECT IMPLEMENTS A CONVOLUTIONAL NEURAL NETWORK (CNN) FOR IMAGE CLASSIFICATION USING TENSORFLOW AND THE MNIST DATASET, FOCUSING ON HANDWRITTEN DIGIT RECOGNITION. THE PROJECT IS MODULARIZED INTO SEVERAL FILES FOR BETTER ORGANIZATION AND REUSABILITY, ENSURING A FUNCTIONAL MODEL THAT TRAINS EFFECTIVELY AND PROVIDES COMPREHENSIVE VISUALIZATIONS OF RESULTS. THE REQUIREMENTS.TXT FILE LISTS ESSENTIAL DEPENDENCIES INCLUDING TENSORFLOW VERSION 2.13.0, MATPLOTLIB 3.7.2, AND NUMPY 1.24.3, ALLOWING EASY INSTALLATION VIA PIP. THE DATA_LOADER.PY SCRIPT HANDLES THE LOADING AND PREPROCESSING OF THE MNIST DATASET, WHICH CONSISTS OF 60,000 TRAINING IMAGES AND 10,000 TEST IMAGES OF 28X28 PIXEL GRAYSCALE DIGITS. IT NORMALIZES PIXEL VALUES TO A 0-1 RANGE, ADDS A CHANNEL DIMENSION FOR CNN INPUT, AND ONE-HOT ENCODES THE 10 CLASS LABELS, OUTPUTTING SHAPES LIKE (60000, 28, 28, 1) FOR TRAINING DATA. NEXT, MODEL.PY DEFINES THE CNN ARCHITECTURE USING KERAS' SEQUENTIAL API: IT INCLUDES TWO CONVOLUTIONAL LAYERS WITH 32 AND 64 FILTERS RESPECTIVELY, EACH FOLLOWED BY 2X2 MAX POOLING; A FLATTEN LAYER; A 128-NEURON DENSE LAYER WITH RELU ACTIVATION; 50% DROPOUT FOR REGULARIZATION; AND A FINAL SOFTMAX LAYER FOR 10-CLASSES OUTPUT. THE MODEL IS COMPILED WITH ADAM OPTIMIZER, CATEGORICAL CROSS-ENTROPY LOSS, AND ACCURACY METRIC, TOTALING ABOUT 225,000 PARAMETERS. THE TRAIN.PY FILE ORCHESTRATES TRAINING: IT LOADS DATA, CREATES THE MODEL, APPLIES EARLY STOPPING TO MONITOR VALIDATION LOSS WITH A PATIENCE OF 3 EPOCHS, AND TRAINS FOR UP TO 10 EPOCHS IN BATCHES OF 128. POST-TRAINING, IT EVALUATES ON THE TEST SET (ACHIEVING AROUND 99% ACCURACY), SAVES THE MODEL AS MNIST_MODEL.H5, AND GENERATES A DUAL-PLOT VISUALIZATION USING MATPLOTLIB—ONE SUBPLOT FOR ACCURACY CURVES (TRAINING AND VALIDATION RISING TO NEAR 99.5%) AND ANOTHER FOR LOSS CURVES (DROPPING TO ABOUT 0.015)—SAVING IT AS TRAINING_HISTORY.PNG. THE PREDICT.PY SCRIPT LOADS THE SAVED MODEL, PREDICTS ON THE FIRST 10 TEST SAMPLES, COMPUTES ARGMAX FOR CLASSES, AND CREATES A VISUALIZATION: THE TOP ROW DISPLAYS SAMPLE IMAGES WITH TRUE AND PREDICTED LABELS, WHILE THE BOTTOM ROW HIGHLIGHTS CORRECT PREDICTIONS OR ERRORS IN RED-TINTED IMAGES, SAVING AS SAMPLE_PREDICTIONS.PNG AND REPORTING SAMPLE ACCURACY (OFTEN 100% FOR SMALL SETS). FINALLY, RUN_PROJECT.PY TIES EVERYTHING TOGETHER BY EXECUTING TRAINING FIRST, THEN PREDICTIONS, PRINTING PROGRESS MESSAGES AND CONFIRMING SAVED FILES. THIS SETUP RUNS IN 2-3 MINUTES ON A CPU, PRODUCING HIGH-ACCURACY RESULTS WITH CLEAR VISUAL INSIGHTS INTO MODEL PERFORMANCE, MAKING IT AN IDEAL STARTER FOR DEEP LEARNING IMAGE CLASSIFICATION TASKS. THE PROJECT DEMONSTRATES BEST PRACTICES LIKE PREPROCESSING, REGULARIZATION, CALLBACKS, AND EVALUATION, EASILY ADAPTABLE FOR OTHER DATASETS OR FRAMEWORKS LIKE PYTORCH.

*OUTPUT* :

<img width="634" height="210" alt="Image" src="https://github.com/user-attachments/assets/7caa5d93-91fc-48be-b823-89ffc64140a0" />
<img width="623" height="108" alt="Image" src="https://github.com/user-attachments/assets/05750ec4-b7ca-4ad4-b7d0-a898e05bceda" />
<img width="947" height="423" alt="Image" src="https://github.com/user-attachments/assets/68d6948b-75c1-4eb6-b096-46e73835cf2b" />
<img width="812" height="368" alt="Image" src="https://github.com/user-attachments/assets/e6711195-6176-449a-87a0-475b4b7adc4e" />
<img width="886" height="402" alt="Image" src="https://github.com/user-attachments/assets/92378b0a-b441-4316-aee7-b74019297ff2" />
<img width="936" height="391" alt="Image" src="https://github.com/user-attachments/assets/0ada441d-21f1-44b5-a0af-bc19b086b544" />
